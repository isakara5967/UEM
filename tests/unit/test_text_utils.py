"""
tests/unit/test_text_utils.py

Text utilities test module.
Tests for Turkish character normalization and text processing.
"""

import pytest

from core.utils.text import (
    normalize_turkish,
    normalize_for_matching,
    TURKISH_TO_ASCII,
)


# ============================================================================
# normalize_turkish Tests
# ============================================================================

class TestNormalizeTurkish:
    """normalize_turkish function tests."""

    def test_empty_string(self):
        """Empty string returns empty string."""
        assert normalize_turkish("") == ""

    def test_none_handling(self):
        """None handling - should not crash."""
        # normalize_turkish expects str, passing empty string instead
        assert normalize_turkish("") == ""

    def test_lowercase_conversion(self):
        """Uppercase letters are converted to lowercase."""
        assert normalize_turkish("MERHABA") == "merhaba"
        assert normalize_turkish("HeLLo") == "hello"

    def test_turkish_u_umlaut(self):
        """Turkish Ã¼ is converted to u."""
        assert normalize_turkish("Ã¼") == "u"
        assert normalize_turkish("Ãœ") == "u"
        assert normalize_turkish("Ã¼zgÃ¼n") == "uzgun"
        assert normalize_turkish("ÃœzgÃ¼n") == "uzgun"

    def test_turkish_o_umlaut(self):
        """Turkish Ã¶ is converted to o."""
        assert normalize_turkish("Ã¶") == "o"
        assert normalize_turkish("Ã–") == "o"
        assert normalize_turkish("Ã¶ÄŸretmen") == "ogretmen"
        assert normalize_turkish("Ã–lÃ§Ã¼") == "olcu"

    def test_turkish_s_cedilla(self):
        """Turkish ÅŸ is converted to s."""
        assert normalize_turkish("ÅŸ") == "s"
        assert normalize_turkish("Å") == "s"
        assert normalize_turkish("ÅŸeker") == "seker"
        assert normalize_turkish("Åikayet") == "sikayet"

    def test_turkish_g_breve(self):
        """Turkish ÄŸ is converted to g."""
        assert normalize_turkish("ÄŸ") == "g"
        assert normalize_turkish("Ä") == "g"
        assert normalize_turkish("daÄŸ") == "dag"
        assert normalize_turkish("SoÄŸuk") == "soguk"

    def test_turkish_dotless_i(self):
        """Turkish Ä± is converted to i."""
        assert normalize_turkish("Ä±") == "i"
        assert normalize_turkish("sÄ±cak") == "sicak"
        assert normalize_turkish("kÄ±sÄ±tlÄ±") == "kisitli"

    def test_turkish_dotted_I(self):
        """Turkish Ä° is converted to I then to i (lowercase)."""
        assert normalize_turkish("Ä°") == "i"
        assert normalize_turkish("Ä°stanbul") == "istanbul"
        assert normalize_turkish("Ä°yi") == "iyi"

    def test_turkish_c_cedilla(self):
        """Turkish Ã§ is converted to c."""
        assert normalize_turkish("Ã§") == "c"
        assert normalize_turkish("Ã‡") == "c"
        assert normalize_turkish("Ã§iÃ§ek") == "cicek"
        assert normalize_turkish("Ã‡ok") == "cok"

    def test_mixed_turkish_chars(self):
        """Multiple Turkish characters in same string."""
        assert normalize_turkish("TÃ¼rkÃ§e") == "turkce"
        assert normalize_turkish("GÃ¼naydÄ±n") == "gunaydin"
        assert normalize_turkish("Ã¶ÄŸrenci") == "ogrenci"
        assert normalize_turkish("Ä°ÅŸÃ§i") == "isci"
        assert normalize_turkish("Åikayet") == "sikayet"

    def test_full_sentence(self):
        """Full Turkish sentence normalization."""
        result = normalize_turkish("Merhaba, nasÄ±lsÄ±n?")
        assert result == "merhaba, nasilsin?"

        result = normalize_turkish("Ã‡ok Ã¼zgÃ¼nÃ¼m, kendimi kÃ¶tÃ¼ hissediyorum.")
        assert result == "cok uzgunum, kendimi kotu hissediyorum."

    def test_numbers_preserved(self):
        """Numbers are preserved."""
        assert normalize_turkish("123") == "123"
        assert normalize_turkish("Test123") == "test123"

    def test_special_chars_preserved(self):
        """Special characters are preserved."""
        assert normalize_turkish("test@email.com") == "test@email.com"
        assert normalize_turkish("Merhaba!") == "merhaba!"
        assert normalize_turkish("Ne zaman?") == "ne zaman?"

    def test_whitespace_preserved(self):
        """Whitespace is preserved."""
        assert normalize_turkish("  test  ") == "  test  "
        assert normalize_turkish("a b c") == "a b c"

    def test_already_ascii(self):
        """ASCII-only text is just lowercased."""
        assert normalize_turkish("hello world") == "hello world"
        assert normalize_turkish("HELLO WORLD") == "hello world"


# ============================================================================
# normalize_for_matching Tests
# ============================================================================

class TestNormalizeForMatching:
    """normalize_for_matching function tests."""

    def test_is_alias_for_normalize_turkish(self):
        """normalize_for_matching is an alias for normalize_turkish."""
        test_strings = [
            "Merhaba",
            "ÃœzgÃ¼n",
            "Åikayet",
            "Ä°stanbul",
            "Ã§ok gÃ¼zel",
        ]

        for s in test_strings:
            assert normalize_for_matching(s) == normalize_turkish(s)

    def test_matching_use_case(self):
        """Test typical matching use case."""
        user_input = "Ã‡ok Ã¼zgÃ¼nÃ¼m"
        pattern = "uzgun"

        normalized_input = normalize_for_matching(user_input)
        assert pattern in normalized_input


# ============================================================================
# TURKISH_TO_ASCII Mapping Tests
# ============================================================================

class TestTurkishToAsciiMapping:
    """TURKISH_TO_ASCII mapping tests."""

    def test_all_mappings_exist(self):
        """All Turkish characters have mappings."""
        expected_chars = ['Ã¼', 'Ãœ', 'Ã¶', 'Ã–', 'ÅŸ', 'Å', 'ÄŸ', 'Ä', 'Ä±', 'Ä°', 'Ã§', 'Ã‡']
        for char in expected_chars:
            assert char in TURKISH_TO_ASCII

    def test_mappings_are_ascii(self):
        """All mapped values are ASCII."""
        for tr_char, ascii_char in TURKISH_TO_ASCII.items():
            assert ord(ascii_char) < 128, f"{ascii_char} is not ASCII"

    def test_case_pairs_match(self):
        """Upper and lower case mappings are consistent."""
        pairs = [
            ('Ã¼', 'Ãœ'),
            ('Ã¶', 'Ã–'),
            ('ÅŸ', 'Å'),
            ('ÄŸ', 'Ä'),
            ('Ã§', 'Ã‡'),
        ]

        for lower, upper in pairs:
            lower_map = TURKISH_TO_ASCII[lower]
            upper_map = TURKISH_TO_ASCII[upper]
            assert lower_map.lower() == upper_map.lower()


# ============================================================================
# Integration Tests with Other Modules
# ============================================================================

class TestIntegrationWithLanguageModules:
    """Integration tests with language modules."""

    def test_situation_builder_pattern_matching(self):
        """Test that normalized patterns work with situation builder."""
        # Simulate pattern matching as done in situation_builder
        message = "Ã‡ok Ã¼zgÃ¼nÃ¼m"
        normalized = normalize_turkish(message)

        # Pattern should match after normalization
        assert "uzgun" in normalized

    def test_risk_scorer_keyword_matching(self):
        """Test that normalized keywords work with risk scorer."""
        # Safety keywords in Turkish
        keywords = ["intihar", "kendine zarar", "olmek"]

        # User message with Turkish chars
        message = "Ã–lmek istiyorum"
        normalized = normalize_turkish(message)

        # Should match the normalized keyword
        assert "olmek" in normalized

    def test_emotional_words_matching(self):
        """Test emotional word matching."""
        positive_words = ["mutlu", "harika", "guzel"]
        negative_words = ["uzgun", "kotu", "sinirli"]

        # Turkish messages
        messages = [
            ("Ã‡ok mutluyum", "positive"),
            ("Kendimi kÃ¶tÃ¼ hissediyorum", "negative"),
            ("ÃœzgÃ¼nÃ¼m", "negative"),
        ]

        for message, expected_type in messages:
            normalized = normalize_turkish(message)
            if expected_type == "positive":
                assert any(w in normalized for w in positive_words)
            else:
                assert any(w in normalized for w in negative_words)

    def test_topic_domain_matching(self):
        """Test topic domain pattern matching."""
        # Patterns for health topic (normalized)
        health_patterns = ["saglik", "hastalik", "doktor", "ilac"]

        # Turkish message about health
        message = "SaÄŸlÄ±k sorunum var, ilaÃ§ almam gerekiyor"
        normalized = normalize_turkish(message)

        # Should match health patterns
        assert any(p in normalized for p in health_patterns)

    def test_intent_pattern_matching(self):
        """Test intent pattern matching."""
        # Intent patterns (normalized)
        help_patterns = ["yardim", "nasil", "ne yapmali"]
        greet_patterns = ["merhaba", "selam", "gunaydin"]

        # Test messages
        test_cases = [
            ("YardÄ±m eder misin?", help_patterns),
            ("NasÄ±l yapmalÄ±yÄ±m?", help_patterns),
            ("Merhaba!", greet_patterns),
            ("GÃ¼naydÄ±n", greet_patterns),
        ]

        for message, patterns in test_cases:
            normalized = normalize_turkish(message)
            assert any(p in normalized for p in patterns), \
                f"'{message}' should match {patterns}"


# ============================================================================
# Edge Cases
# ============================================================================

class TestEdgeCases:
    """Edge case tests."""

    def test_very_long_string(self):
        """Very long strings are handled correctly."""
        long_string = "TÃ¼rkÃ§e " * 1000
        result = normalize_turkish(long_string)
        assert len(result) > 0
        assert "Ã¼" not in result

    def test_unicode_emojis(self):
        """Emojis are preserved."""
        result = normalize_turkish("Merhaba ğŸ˜Š")
        assert "merhaba" in result
        assert "ğŸ˜Š" in result

    def test_repeated_turkish_chars(self):
        """Repeated Turkish characters are all converted."""
        result = normalize_turkish("Ã¼Ã¼Ã¼Ã¼Ã¼")
        assert result == "uuuuu"

    def test_mixed_unicode(self):
        """Mixed Unicode characters are handled."""
        result = normalize_turkish("Ğ¢ĞµÑÑ‚ TÃ¼rkÃ§e Ù…Ø±Ø­Ø¨Ø§")
        assert "turkce" in result
